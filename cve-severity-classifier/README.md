# CVE Severity Classifier (TF‑IDF + SVM)

Projet 3.2 — **Classification de la sévérité des CVE à partir du texte** (Low/Medium/High/Critical).

Ce dépôt contient :
- un pipeline **reproductible** (prétraitement + TF‑IDF + LinearSVC),
- des scripts `train`, `evaluate`, `predict`,
- l’export du modèle (`.joblib`), des métriques (`.json`) et de la matrice de confusion (`.png`),
- une extraction de **mots‑clés discriminants** par classe (interprétabilité).

## 1) Installation
```bash
pip install -r requirements.txt
```

## 2) Dataset
Dataset public Hugging Face :
- `CIRCL/vulnerability-scores`

Le téléchargement est automatique via `datasets`.

> Sur Colab, le warning `HF_TOKEN` est normal : l’authentification est optionnelle pour un dataset public.

## 3) Entraîner
```bash
python -m src.train --out models/svm_tfidf.joblib
```

Paramètres clés :
- `--border 0.20` : supprime les scores proches de 4/7/9 (réduction du bruit)
- `--min-len 40` : supprime les descriptions trop courtes
- `--c 2.0` : paramètre C du LinearSVC
- `--max-train N` : sous‑ensemble pour tests rapides

Exemple (config recommandée) :
```bash
python -m src.train --border 0.20 --min-len 40 --c 2.0 --out models/svm_tfidf.joblib
```

## 4) Évaluer + matrice de confusion + mots-clés
```bash
python -m src.evaluate --model models/svm_tfidf.joblib --outdir results
```

Sorties :
- `results/metrics.json`
- `results/confusion_matrix.png`
- `results/keywords_by_class.txt`

## 5) Prédire
### a) Un texte
```bash
python -m src.predict --model models/svm_tfidf.joblib --text "A remote attacker can execute arbitrary code via ..."
```

### b) Un fichier (1 description par ligne)
```bash
python -m src.predict --model models/svm_tfidf.joblib --input descriptions.txt --output predictions.csv
```

## 6) Tests rapides
```bash
pytest -q
```

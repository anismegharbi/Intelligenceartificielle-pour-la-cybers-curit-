from __future__ import annotations
import argparse
from pathlib import Path

from datasets import load_dataset
from joblib import dump

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC

from .utils import prepare_dataset

def build_model(c: float, ngram_max: int, min_df: int, max_df: float) -> Pipeline:
    return Pipeline([
        ("tfidf", TfidfVectorizer(
            lowercase=True,
            stop_words="english",
            ngram_range=(1, ngram_max),
            min_df=min_df,
            max_df=max_df,
            sublinear_tf=True,
        )),
        ("svm", LinearSVC(class_weight="balanced", C=c))
    ])

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--dataset", default="CIRCL/vulnerability-scores")
    ap.add_argument("--border", type=float, default=0.20)
    ap.add_argument("--min-len", type=int, default=40)
    ap.add_argument("--use-title", action="store_true")
    ap.add_argument("--use-cpes", action="store_true")
    ap.add_argument("--c", type=float, default=2.0)
    ap.add_argument("--ngram-max", type=int, default=2)
    ap.add_argument("--min-df", type=int, default=3)
    ap.add_argument("--max-df", type=float, default=0.9)
    ap.add_argument("--max-train", type=int, default=0, help="0 = all; sinon sous-ensemble")
    ap.add_argument("--out", default="models/svm_tfidf.joblib")
    args = ap.parse_args()

    ds = load_dataset(args.dataset)
    train_df = ds["train"].to_pandas()
    test_df = ds["test"].to_pandas()

    prepared = prepare_dataset(
        train_df=train_df,
        test_df=test_df,
        border=args.border,
        min_len=args.min_len,
        use_title=args.use_title,
        use_cpes=args.use_cpes,
    )

    X_train, y_train = prepared.X_train, prepared.y_train
    if args.max_train and args.max_train > 0:
        X_train = X_train.iloc[:args.max_train]
        y_train = y_train.iloc[:args.max_train]

    model = build_model(args.c, args.ngram_max, args.min_df, args.max_df)
    model.fit(X_train, y_train)

    out_path = Path(args.out)
    out_path.parent.mkdir(parents=True, exist_ok=True)
    dump(model, out_path)

    print(f"[OK] Modèle sauvegardé: {out_path}")
    print(f"Train utilisé: {len(X_train)} | Test: {len(prepared.X_test)}")

if __name__ == "__main__":
    main()

from __future__ import annotations
import argparse, json
from pathlib import Path

import numpy as np
import matplotlib.pyplot as plt

from datasets import load_dataset
from joblib import load
from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay

from .utils import prepare_dataset

def extract_keywords_by_class(model, top_k: int = 25) -> str:
    tfidf = model.named_steps["tfidf"]
    svm = model.named_steps["svm"]
    feature_names = np.array(tfidf.get_feature_names_out())
    classes = svm.classes_

    out = []
    for i, cls in enumerate(classes):
        top = np.argsort(svm.coef_[i])[-top_k:]
        out.append("====================================")
        out.append(f"Classe: {cls}")
        out.append(", ".join(feature_names[top]))
        out.append("")
    return "\n".join(out)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--dataset", default="CIRCL/vulnerability-scores")
    ap.add_argument("--model", required=True)
    ap.add_argument("--outdir", default="results")
    ap.add_argument("--border", type=float, default=0.20)
    ap.add_argument("--min-len", type=int, default=40)
    ap.add_argument("--use-title", action="store_true")
    ap.add_argument("--use-cpes", action="store_true")
    ap.add_argument("--topk", type=int, default=25)
    args = ap.parse_args()

    outdir = Path(args.outdir)
    outdir.mkdir(parents=True, exist_ok=True)

    model = load(args.model)

    ds = load_dataset(args.dataset)
    train_df = ds["train"].to_pandas()
    test_df = ds["test"].to_pandas()

    prepared = prepare_dataset(
        train_df=train_df,
        test_df=test_df,
        border=args.border,
        min_len=args.min_len,
        use_title=args.use_title,
        use_cpes=args.use_cpes,
    )

    pred = model.predict(prepared.X_test)
    acc = float(accuracy_score(prepared.y_test, pred))
    report = classification_report(prepared.y_test, pred, output_dict=True)

    metrics = {
        "accuracy": acc,
        "n_train_after_filters": int(len(prepared.y_train)),
        "n_test": int(len(prepared.y_test)),
        "filters": {
            "cvss_version": "v3.1 only",
            "border": args.border,
            "min_len": args.min_len,
            "use_title": bool(args.use_title),
            "use_cpes": bool(args.use_cpes),
        },
        "classification_report": report,
    }
    (outdir/"metrics.json").write_text(json.dumps(metrics, indent=2, ensure_ascii=False), encoding="utf-8")

    # Confusion matrix
    fig, ax = plt.subplots(figsize=(7,6))
    ConfusionMatrixDisplay.from_predictions(prepared.y_test, pred, ax=ax, colorbar=True, values_format="d")
    ax.set_title(f"Confusion Matrix â€” Accuracy={acc:.4f}")
    plt.tight_layout()
    fig.savefig(outdir/"confusion_matrix.png", dpi=200)
    plt.close(fig)

    # Keywords
    kw = extract_keywords_by_class(model, top_k=args.topk)
    (outdir/"keywords_by_class.txt").write_text(kw, encoding="utf-8")

    print(f"[OK] Accuracy: {acc:.4f}")
    print(f"[OK] outputs -> {outdir}")

if __name__ == "__main__":
    main()
